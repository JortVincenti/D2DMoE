============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
rm: refusing to remove '.' or '..' directory: skipping 'shared/results/effbench_logs/.'
rm: refusing to remove '.' or '..' directory: skipping 'shared/results/effbench_logs/..'
[dist initialize] env variable "RANK" is not set, use cuda:0 as the device
[02-04 23:38:26] (jvincenti/D2DMoE/dist.py, line  28)=> [dist initialize] env variable "RANK" is not set, use cuda:0 as the device
[02-04 23:38:26] (jvincenti/D2DMoE/dist.py, line  28)=> [dist initialize] env variable "RANK" is not set, use cuda:0 as the device
[02-04 23:38:26] (jvincenti/D2DMoE/dist.py, line  28)=> [dist initialize] env variable "RANK" is not set, use cuda:0 as the device
[02-04 23:38:26] (jvincenti/D2DMoE/dist.py, line  28)=> [dist initialize] env variable "RANK" is not set, use cuda:0 as the device
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 178)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 179)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 180)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 178)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 179)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 180)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 178)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 179)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 180)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 178)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 179)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 180)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 178)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 179)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[02-04 23:38:26] (oE/utils_var/arg_util.py, line 180)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[02-04 23:38:26] (oE/scripts/d2dmoe_var.py, line 350)=> Exp names: ['TINYIMAGENET_PATH_var_d16_MQWFVKRM', 'TINYIMAGENET_PATH_mha_rep_distill_ZZEYF6VB', 'TINYIMAGENET_PATH_enforce_sparsity_LTCYPYXW', 'TINYIMAGENET_PATH_dsti_expert_split_O7HDH7XG', 'TINYIMAGENET_PATH_dsti_router_6XU5AM7Y']
[02-04 23:38:26] (oE/scripts/d2dmoe_var.py, line 351)=> Display names: ['VAR', 'MHA distillation', 'Sparsity enforcement', 'DSTI expert split', 'DSTI']
[02-04 23:38:26] (oE/scripts/d2dmoe_var.py, line 352)=> SLURM JIDs: []

JOB STATISTICS
==============
Job ID: 9772844
Cluster: snellius
User/Group: jvincenti/jvincenti
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:10
CPU Efficiency: 2.06% of 00:08:06 core-walltime
Job Wall-clock time: 00:00:27
Memory Utilized: 2.22 MB
Memory Efficiency: 0.00% of 120.00 GB
