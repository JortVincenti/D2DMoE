






=======================================================   RESTART [01-17 18:04:32]   =======================================================
[01-17 18:04:32] (oE/utils_var/arg_util.py, line 258)=> [tf32] [precis] torch.get_float32_matmul_precision(): highest
[01-17 18:04:32] (oE/utils_var/arg_util.py, line 259)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: False
[01-17 18:04:32] (oE/utils_var/arg_util.py, line 260)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: False







=======================================================   RESTART [01-17 18:09:34]   =======================================================
[01-17 18:09:34] (oE/utils_var/arg_util.py, line 258)=> [tf32] [precis] torch.get_float32_matmul_precision(): highest
[01-17 18:09:34] (oE/utils_var/arg_util.py, line 259)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: False
[01-17 18:09:34] (oE/utils_var/arg_util.py, line 260)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: False







=======================================================   RESTART [01-17 18:29:12]   =======================================================
[01-17 18:29:12] (oE/utils_var/arg_util.py, line 258)=> [tf32] [precis] torch.get_float32_matmul_precision(): highest
[01-17 18:29:12] (oE/utils_var/arg_util.py, line 259)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: False
[01-17 18:29:12] (oE/utils_var/arg_util.py, line 260)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: False
